---
title: "Visium part 2"
author: "Givanna Putri"
date: "2024-11-20"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction

In this part of the visium workshop, we will introduce steps to perform Quality Control
(QC) and normalisation on visium data.

## Load libraries and data

```{r message=FALSE}
library(Seurat)
library(qs)
library(ggplot2)
library(scales)
```

We will be using the Seurat object that we have previously loaded in [part 1](visium_01.html).

```{r}
dat <- qread("output/visium/visium_seurat.qs")
dat
```

## Quality Control (QC)

QC is part of data pre-processing process.
The main purpose of it is to remove stuff (e.g., spots and genes) that are of low quality.
If not removed, these can negatively impact your downstream analyses, and potentially
leading to false findings and interpretations.

Performing QC on the data can be seen as a delicate balancing act.
Overly aggressive QC will yield very clean data, but at the same token, can remove
stuff that would have otherwise led to an interesting biology.
Overly liberal QC may include many dud stuff (or just plain noise) that makes interpretation hard. 
Thus, it is always important to inspect the result of a given QC strategy,
and fine tune as required.

### QC genes

By default, `Load10X_Spatial` will load up all the genes in the data.
However, it is highly likely for some genes to only be expressed (have raw count > 0) 
in only a small number of spots.
It may well be that there are only really a tiny number of spots that expressed this gene
that it may well be a noise.
Thus, it is best to remove them as otherwise you may be running the risk of them 
negatively impacting further downstream analyses.

To work out the number of spots expressing a given gene, you can use a histogram.

```{r}
# Count how many spots each gene is expressed in.
spots_per_gene <- rowSums(dat[["Spatial"]]$counts > 0)

# Plot as histogram
# Have to convert spots_per_gene to data.frame first, the column is spots
ggplot(data.frame(spots = spots_per_gene), aes(x=spots)) + 
  geom_histogram(binwidth = 1, colour = 'blue') +
  geom_vline(xintercept = 100, colour = 'red') +
  theme_minimal() +
  labs(title = "Number of Spots per Gene",
       x = "Number of Spots",
       y = "Number of Genes") +
  scale_x_continuous(breaks = pretty_breaks(10)) +
  scale_y_continuous(breaks = pretty_breaks(10))

```

The histogram above illustrates how many genes (y-axis) are expressed in
how many spots (x-axis).
For example, the left most bar shows there are 12 genes that are not expressed
in any spots at all.

From the histogram, we can see the distribution of the gene expressions, and work
out a sensible threshold to filter out genes.
In other words, identifying the minimum number of spots a gene must be expressed
for it to be included in our data.
For this dataset, we will set the threshold to 100, i.e. for a gene to be included,
it needs to be expressed in at least 100 spots, which is around 2.3% of total 
spots we have in the data.

```{r warning=FALSE}
# names will give you the gene names
genes_to_keep <- names(spots_per_gene[spots_per_gene >= 100])

# Subset the Seurat object
dat_fil <- subset(dat, features = genes_to_keep)
```

<hr>

<details>
<summary>Setting the threshold</summary>

<hr>

The threshold 100 is not fixed. 
This will vary depending on the dataset you have on hand.
So adjust this as you see fit.

You may notice that the value 100 seems high, especially if you have some experience
QCing some scRNAseq data.
However, it is worth remembering that visium is a spot based technology and that
each spot captures more than 1 cell.

</details>

<hr>

### QC spots

In addition to QC the genes, we should also QC the spots to make sure that we remove
spots that are low quality.
These could be spots that lie outside of the tissue, or have low library size or 
low number of genes expressed, or expressed high mitochondrial genes.

#### Using ImageJ to remove spots outside of the tissue

The vanilla 10X SpaceRanger pipeline automatically identifies the spots that overlap with tissue. 
This is not always consistent or reliable. Therefore, there is no reason why 

#### Using Loupe Browser to remove spots outside of the tissue

To identify spots that lie outside of the tissue, we can use the Loupe Browser software.
Loupe browser is a visualisation software produced by 10x to make it easier for
users to interact with their data.
It can be downloaded from [10x website](https://www.10xgenomics.com/support/software/loupe-browser/latest).

To load the data up to Loupe browser, you need to have on hand the Loupe browser file
generated by spaceranger count.
For this dataset, you can download it from 10x website
(choose Visium CytoAssist v2 P2 crc on the right panel): 
https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression/dataset-human-crc.

Using the loop browser, you can see which spots lie outside of the tissue, mark them,
and export their barcodes out:

<video width="600" height="500" controls>
  <source src="assets/visium_loupe_demo.mp4" type="video/mp4">
</video>

<hr>

<details>
<summary>Removing spots</summary>

<hr>

If you happen to make a mistake when using the lasso tool, and accidentally selected
spots that you meant to keep, use the eraser tool to "erase" those spots from the list by selecting them.

</details>

<hr>

After exporting the spots barcode in a csv file, we can load it up and remove them from the seurat object:

```{r warning=FALSE}
spots_to_remove <- read.csv("data/visium/spots_to_remove_v2.csv")

# add it as a metadata
dat_fil[[]]$remove_spot_from_loupe <- Cells(dat_fil) %in% spots_to_remove$Barcode

# store as separate object just for demo
dat_fil <- subset(x = dat_fil, remove_spot_from_loupe == FALSE)
dat_fil
```

### QC spots based on library size and genes expressed

We should also remove spots which express low library size and/or low number of genes expressed.

Few plots we can draw to check this are violin plots, histogram, and plain scatter plots:

```{r fig.dim=c(10,8)}
plt1 <- ggplot(dat_fil[[]], aes(x=nCount_Spatial)) + geom_histogram(bins = 100) +
  theme_classic() +
  scale_y_continuous(breaks = pretty_breaks(10)) +
  scale_x_continuous(breaks = pretty_breaks(10)) 
plt2 <- ggplot(dat_fil[[]], aes(x=nFeature_Spatial)) + geom_histogram(bins = 100) +
  theme_classic() +
  scale_y_continuous(breaks = pretty_breaks(10)) +
  scale_x_continuous(breaks = pretty_breaks(10)) 

plt3 <- VlnPlot(dat_fil, features = c("nCount_Spatial", "nFeature_Spatial"))

plt4 <- FeatureScatter(dat_fil, feature1 = "nCount_Spatial", feature2 = "nFeature_Spatial") +
  scale_y_continuous(breaks = pretty_breaks(10)) +
  scale_x_continuous(breaks = pretty_breaks(10)) +
  theme_bw()

plt1 + plt2 + plt3 + plt4
```

The histograms and violin plots are great for determining the minimum cutoff for library
size and/or number of genes expressed, while the scatter plot is handy to 
check whether the spots with low library size also has low number of genes expressed, 
which make them the prime candidates for removal.

For this workshop, we will exclude spots that express less than 3000 genes.
Incidentally, this threshold will also automatically exclude spots with small library size.

```{r warning=FALSE}
dat_fil <- subset(x = dat_fil, nFeature_Spatial >= 3000)
dat_fil
```

<hr>

<details>
<summary>Good know</summary>

<hr>

<h3> Keeping spots with high library size </h3>

Unlike single cell in which cells that have high library size are often removed because
they may well represent doublets or multiplets, for visium data, spots with high library size 
may not necessarily mean bad spots as visium data is not single cell resolution.
Those spots may well just contain an assortment of cell types which may lead to
interesting biology!

</details>

<hr>

### QC spots based on mitochondria genes expression

Just like in single cell, we can also QC the spots based on the percentage of mitochondria genes expressed.
Spots that have excessively high expression of mitochondria genes may contain
low quality or dying cells.

```{r fig.dim=c(5, 8)}
# This function will compute, for each spot, percentage of transcripts that mapped to mitochondria genes
dat_fil[['percent_mt']] <- PercentageFeatureSet(dat_fil, pattern = '^MT-')

# Visualize them
plt1 <- VlnPlot(dat_fil, features = "percent_mt")
plt2 <- FeatureScatter(dat_fil, feature1 = 'nCount_Spatial', feature2 = 'percent_mt')

plt1 + plt2
```

We will remove spots that have > 12% mitochondria genes.

```{r warning=FALSE}
dat_fil <- subset(dat_fil, subset = percent_mt < 12)
dat_fil
```

After QC, we ended up with 3,950 spots.

### Export data out

```{r}
qsave(dat_fil, "output/visium_seurat_qced.qs")
```

## Normalisation

Why is this necessary?
The same reason as any other RNA seq based protocol (including single cell).
Differences in library size may well be due to variances in sampling of RNA molecules.
During library preparation, it is not possible to capture all molecules and sequence them.
Thus, the unevenness of library sizes and differences in gene expression across spots, 
may well be due to variance in sampling.
There are also other technical variations that contributed to the differences that need to be accounted for,
e.g., Probe hybridization efficiency and PCR amplification biases.

Normalisation aims to adjust differences introduced due to technical variations.
In single cell, there are many methods that have been developed to do this (see [here](https://www.nature.com/articles/s41592-023-01814-1) for benchmarking paper).
Admittedly, not all of them will be suitable for visium data.
For this tutorial, we will demonstrate classic log normalisation and SCTransform.

### Running SCTransform

Briefly SCTransform fits a regularised negative binomial model to the raw count matrix, 
using sequencing depth as a covariate.

Note, SCT requires glmGamPoi package: `BiocManager::install('glmGamPoi')`

```{r message=FALSE}
# Might need to increase the size limit for global variables so parallel workers
# can access it. 2GB should be sufficient.
options(future.globals.maxSize = 2000 * 1024^2)


# Note, return.only.var.genes can be set to TRUE if we want to get back 
# the expression of only highly variable genes in scale.data
dat_fil <- SCTransform(dat_fil, assay = "Spatial", verbose = TRUE, return.only.var.genes = FALSE)
# Inspect after
dat_fil
```

By default, SCTransform will store the output in a different assay called "SCT".

```{r}
head(dat_fil[['SCT']]$data, c(20, 5))
```

<hr>

<details>
<summary>Note on layers</summary>

<hr>

<h3> Keeping spots with high library size </h3>

As previously discussed in the beginning, an assay can contain multiple layers.
After running SCTransfrom, you shall notice a new assay call SCT containing SCTransformed counts.
Specifically, counts layer contains corrected UMI counts,
data contains log1p - log(1 + counts) of the corrected UMI counts,
scale.data contains the counts in the data layer transformed using pearson residuals 
calculated by SCTransform.

</details>

<hr>

### Comparison with log normalisation

Log normalisation is commonly used for single cell data.
It is also widely used for normalising visium data where for each spot and gene,
we divide the expression by the spot's library size and multiply the value by a size factor
(say 10,000).
Then we perform log1p operation where we run logarithmic transformation after adding value of 1.
Why the addition, because log of 0 is infinity.

```{r}
# By default, this will run log CPTT
# The data layer will contain the normalised counts.
# The counts layer will contain the unnormalised count.
dat_fil <- NormalizeData(dat_fil, verbose = FALSE, assay = "Spatial")
dat_fil
```

Upon running this, you will notice an additional layer in the Spatial assay call `data`
which contains the output of log normalisation function.

We can plot the output of SCTransform, log normalisation, and raw count 
for a gene (say COL1A1), side by side to see what they look like.

```{r}
# Important to change assay before plotting to make sure it is the right one.

DefaultAssay(object = dat_fil) <- "SCT"
plt_sct <- SpatialFeaturePlot(
  dat_fil,
  features = "COL1A1",
  image.alpha = 0.5,
  pt.size.factor = 4
) + ggtitle("SCT")


DefaultAssay(object = dat_fil) <- "Spatial"
plt_lognorm <- SpatialFeaturePlot(
  dat_fil,
  features = "COL1A1",
  image.alpha = 0.5,
  pt.size.factor = 4
) + ggtitle("Log Norm")

# Plot raw data for comparison
plt_raw <- SpatialFeaturePlot(
  dat_fil,
  features = "COL1A1",
  image.alpha = 0.5,
  pt.size.factor = 4,
  slot = 'counts'
) + ggtitle("Raw")

# Put all 3 plots side by side for comparison
plt_raw + plt_sct + plt_lognorm

```

<hr>

<details>
<summary>SCTransform vs Log Norm</summary>

<hr>

There are pros and cons on choosing either SCT or log normalisation.
From the plot, you can see they are different.
Literatures say SCT mitigates the correlation between library size and normalised counts
which log normalisation failed to do so.
On the other hand, log normalisation is very simple (you can compute it by hand if you like!)
and fast to compute, very well established, intuitive, and compatible with a variety of analysis tools and pipelines.
While SCT may be more robust for data with high variability in sequencing depth,
at the end of the day, choose whichever method that you are comfortable with.

</details>

<hr>

For this tutorial, we will use the normalised counts generated by SCTransform.

```{r}
# Set the default assay to SCT
DefaultAssay(dat_fil) <- "SCT"

# save so we can reload if we need to
qsave(dat_fil, "output/visium_seurat_qced_norm.qs")
```


